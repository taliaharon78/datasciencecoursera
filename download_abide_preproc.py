{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJbMFoBu00VAT8YIsFAZCL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taliaharon78/datasciencecoursera/blob/master/download_abide_preproc.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "B4A1EECu23Go",
        "outputId": "8647995d-734d-4a6b-a8bf-9c512a2c1ea1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-e4f8879658a2>\"\u001b[0;36m, line \u001b[0;32m274\u001b[0m\n\u001b[0;31m    collect_and_download(-d reho, -p cpac, -s nofilt_noglobal, -o /path/to/local/download/dir)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "# download_abide_preproc.py\n",
        "#\n",
        "# Author: Daniel Clark, 2015\n",
        "# Updated to python 3 and to support downloading by DX, Cameron Craddock, 2019\n",
        "\n",
        "\"\"\"\n",
        "This script downloads data from the Preprocessed Connetomes Project's\n",
        "ABIDE Preprocessed data release and stores the files in a local\n",
        "directory; users specify derivative, pipeline, strategy, and optionally\n",
        "age ranges, sex, site of interest\n",
        "Usage:\n",
        "    python download_abide_preproc.py -d <derivative> -p <pipeline>\n",
        "                                     -s <strategy> -o <out_dir>\n",
        "                                     [-lt <less_than>] [-gt <greater_than>]\n",
        "                                     [-x <sex>] [-t <site>]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Main collect and download function\n",
        "def collect_and_download(derivative, pipeline, strategy, out_dir, less_than, greater_than, site, sex, diagnosis):\n",
        "    \"\"\"\n",
        "    Function to collect and download images from the ABIDE preprocessed\n",
        "    directory on FCP-INDI's S3 bucket\n",
        "    Parameters\n",
        "    ----------\n",
        "    derivative : string\n",
        "        derivative or measure of interest\n",
        "    pipeline : string\n",
        "        pipeline used to process data of interest\n",
        "    strategy : string\n",
        "        noise removal strategy used to process data of interest\n",
        "    out_dir : string\n",
        "        filepath to a local directory to save files to\n",
        "    less_than : float\n",
        "        upper age (years) threshold for participants of interest\n",
        "    greater_than : float\n",
        "        lower age (years) threshold for participants of interest\n",
        "    site : string\n",
        "        acquisition site of interest\n",
        "    sex : string\n",
        "        'M' or 'F' to indicate whether to download male or female data\n",
        "    diagnosis : string\n",
        "        'asd', 'tdc', or 'both' corresponding to the diagnosis of the\n",
        "        participants for whom data should be downloaded\n",
        "    Returns\n",
        "    -------\n",
        "    None\n",
        "        this function does not return a value; it downloads data from\n",
        "        S3 to a local directory\n",
        "    :param derivative: \n",
        "    :param pipeline: \n",
        "    :param strategy: \n",
        "    :param out_dir: \n",
        "    :param less_than: \n",
        "    :param greater_than: \n",
        "    :param site: \n",
        "    :param sex:\n",
        "    :param diagnosis:\n",
        "    :return: \n",
        "    \"\"\"\n",
        "\n",
        "    # Import packages\n",
        "    import os\n",
        "    import urllib.request as request\n",
        "\n",
        "    # Init variables\n",
        "    mean_fd_thresh = 0.2\n",
        "    s3_prefix = 'https://s3.amazonaws.com/fcp-indi/data/Projects/'\\\n",
        "                'ABIDE_Initiative'\n",
        "    s3_pheno_path = '/'.join([s3_prefix, 'Phenotypic_V1_0b_preprocessed1.csv'])\n",
        "\n",
        "    # Format input arguments to be lower case, if not already\n",
        "    derivative = derivative.lower()\n",
        "    pipeline = pipeline.lower()\n",
        "    strategy = strategy.lower()\n",
        "\n",
        "    # Check derivative for extension\n",
        "    if 'roi' in derivative:\n",
        "        extension = '.1D'\n",
        "    else:\n",
        "        extension = '.nii.gz'\n",
        "\n",
        "    # If output path doesn't exist, create it\n",
        "    if not os.path.exists(out_dir):\n",
        "        print('Could not find {0}, creating now...'.format(out_dir))\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    # Load the phenotype file from S3\n",
        "    s3_pheno_file = request.urlopen(s3_pheno_path)\n",
        "    pheno_list = s3_pheno_file.readlines()\n",
        "    print(pheno_list[0])\n",
        "\n",
        "    # Get header indices\n",
        "    header = pheno_list[0].decode().split(',')\n",
        "    try:\n",
        "        site_idx = header.index('SITE_ID')\n",
        "        file_idx = header.index('FILE_ID')\n",
        "        age_idx = header.index('AGE_AT_SCAN')\n",
        "        sex_idx = header.index('SEX')\n",
        "        dx_idx = header.index('DX_GROUP')\n",
        "        mean_fd_idx = header.index('func_mean_fd')\n",
        "    except Exception as exc:\n",
        "        err_msg = 'Unable to extract header information from the pheno file: {0}\\nHeader should have pheno info:' \\\n",
        "                  ' {1}\\nError: {2}'.format(s3_pheno_path, str(header), exc)\n",
        "        raise Exception(err_msg)\n",
        "\n",
        "    # Go through pheno file and build download paths\n",
        "    print('Collecting images of interest...')\n",
        "    s3_paths = []\n",
        "    for pheno_row in pheno_list[1:]:\n",
        "\n",
        "        # Comma separate the row\n",
        "        cs_row = pheno_row.decode().split(',')\n",
        "\n",
        "        try:\n",
        "            # See if it was preprocessed\n",
        "            row_file_id = cs_row[file_idx]\n",
        "            # Read in participant info\n",
        "            row_site = cs_row[site_idx]\n",
        "            row_age = float(cs_row[age_idx])\n",
        "            row_sex = cs_row[sex_idx]\n",
        "            row_dx = cs_row[dx_idx]\n",
        "            row_mean_fd = float(cs_row[mean_fd_idx])\n",
        "        except Exception as e:\n",
        "            err_msg = 'Error extracting info from phenotypic file, skipping...'\n",
        "            print(err_msg)\n",
        "            continue\n",
        "\n",
        "        # If the filename isn't specified, skip\n",
        "        if row_file_id == 'no_filename':\n",
        "            continue\n",
        "        # If mean fd is too large, skip\n",
        "        if row_mean_fd >= mean_fd_thresh:\n",
        "            continue\n",
        "\n",
        "        # Test phenotypic criteria (three if's looks cleaner than one long if)\n",
        "        # Test sex\n",
        "        if (sex == 'M' and row_sex != '1') or (sex == 'F' and row_sex != '2'):\n",
        "            continue\n",
        "\n",
        "        if (diagnosis == 'asd' and row_dx != '1') or (diagnosis == 'tdc' and row_dx != '2'):\n",
        "            continue\n",
        "\n",
        "        # Test site\n",
        "        if site is not None and site.lower() != row_site.lower():\n",
        "            continue\n",
        "        # Test age range\n",
        "        if greater_than < row_age < less_than:\n",
        "            filename = row_file_id + '_' + derivative + extension\n",
        "            s3_path = '/'.join([s3_prefix, 'Outputs', pipeline, strategy, derivative, filename])\n",
        "            print('Adding {0} to download queue...'.format(s3_path))\n",
        "            s3_paths.append(s3_path)\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "    # And download the items\n",
        "    total_num_files = len(s3_paths)\n",
        "    for path_idx, s3_path in enumerate(s3_paths):\n",
        "        rel_path = s3_path.lstrip(s3_prefix)\n",
        "        download_file = os.path.join(out_dir, rel_path)\n",
        "        download_dir = os.path.dirname(download_file)\n",
        "        if not os.path.exists(download_dir):\n",
        "            os.makedirs(download_dir)\n",
        "        try:\n",
        "            if not os.path.exists(download_file):\n",
        "                print('Retrieving: {0}'.format(download_file))\n",
        "                request.urlretrieve(s3_path, download_file)\n",
        "                print('{0:3f}% percent complete'.format(100*(float(path_idx+1)/total_num_files)))\n",
        "            else:\n",
        "                print('File {0} already exists, skipping...'.format(download_file))\n",
        "        except Exception as exc:\n",
        "            print('There was a problem downloading {0}.\\n Check input arguments and try again.'.format(s3_path))\n",
        "\n",
        "    # Print all done\n",
        "    print('Done!')\n",
        "\n",
        "\n",
        "# Make module executable\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # Import packages\n",
        "    import argparse\n",
        "    import os\n",
        "    import sys\n",
        "\n",
        "    # Init argument parser\n",
        "    parser = argparse.ArgumentParser(description=__doc__)\n",
        "\n",
        "    # Required arguments\n",
        "    parser.add_argument('-a', '--asd', required=False, default=False, action='store_true',\n",
        "                        help='Only download data for participants with ASD.'\n",
        "                             ' Specifying neither or both -a and -c will download data from all participants.')\n",
        "    parser.add_argument('-c', '--tdc', required=False, default=False, action='store_true',\n",
        "                        help='Only download data for participants who are typically developing controls.'\n",
        "                             ' Specifying neither or both -a and -c will download data from all participants.')\n",
        "    parser.add_argument('-d', '--derivative', nargs=1, required=True, type=str,\n",
        "                        help='Derivative of interest (e.g. \\'reho\\')')\n",
        "    parser.add_argument('-p', '--pipeline', nargs=1, required=True, type=str,\n",
        "                        help='Pipeline used to preprocess the data (e.g. \\'cpac\\')')\n",
        "    parser.add_argument('-s', '--strategy', nargs=1, required=True, type=str,\n",
        "                        help='Noise-removal strategy used during preprocessing (e.g. \\'nofilt_noglobal\\'')\n",
        "    parser.add_argument('-o', '--out_dir', nargs=1, required=True, type=str,\n",
        "                        help='Path to local folder to download files to')\n",
        "\n",
        "    # Optional arguments\n",
        "    parser.add_argument('-lt', '--less_than', nargs=1, required=False,\n",
        "                        type=float, help='Upper age threshold (in years) of participants to download (e.g. for '\n",
        "                                         'subjects 30 or younger, \\'-lt 31\\')')\n",
        "    parser.add_argument('-gt', '--greater_than', nargs=1, required=False,\n",
        "                        type=int, help='Lower age threshold (in years) of participants to download (e.g. for '\n",
        "                                       'subjects 31 or older, \\'-gt 30\\')')\n",
        "    parser.add_argument('-t', '--site', nargs=1, required=False, type=str,\n",
        "                        help='Site of interest to download from (e.g. \\'Caltech\\'')\n",
        "    parser.add_argument('-x', '--sex', nargs=1, required=False, type=str,\n",
        "                        help='Participant sex of interest to download only (e.g. \\'M\\' or \\'F\\')')\n",
        "\n",
        "    # Parse and gather arguments\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # Init variables\n",
        "    desired_derivative = args.derivative[0].lower()\n",
        "    desired_pipeline = args.pipeline[0].lower()\n",
        "    desired_strategy = args.strategy[0].lower()\n",
        "    download_data_dir = os.path.abspath(args.out_dir[0])\n",
        "\n",
        "    # Try and init optional arguments\n",
        "\n",
        "    # for diagnosis if both ASD and TDC flags are set to true or false, we download both\n",
        "    desired_diagnosis = ''\n",
        "    if args.tdc == args.asd:\n",
        "        desired_diagnosis = 'both'\n",
        "        print('Downloading data for ASD and TDC participants')\n",
        "    elif args.tdc:\n",
        "        desired_diagnosis = 'tdc'\n",
        "        print('Downloading data for TDC participants')\n",
        "    elif args.asd:\n",
        "        desired_diagnosis = 'asd'\n",
        "        print('Downloading data for ASD participants')\n",
        "\n",
        "    try:\n",
        "        desired_age_max = args.less_than[0]\n",
        "        print('Using upper age threshold of {0:d}...'.format(desired_age_max))\n",
        "    except TypeError:\n",
        "        desired_age_max = 200.0\n",
        "        print('No upper age threshold specified')\n",
        "\n",
        "    try:\n",
        "        desired_age_min = args.greater_than[0]\n",
        "        print('Using lower age threshold of {0:d}...'.format(desired_age_min))\n",
        "    except TypeError:\n",
        "        desired_age_min = -1.0\n",
        "        print('No lower age threshold specified')\n",
        "\n",
        "    try:\n",
        "        desired_site = args.site[0]\n",
        "    except TypeError:\n",
        "        desired_site = None\n",
        "        print('No site specified, using all sites...')\n",
        "\n",
        "    try:\n",
        "        desired_sex = args.sex[0].upper()\n",
        "        if desired_sex == 'M':\n",
        "            print('Downloading only male subjects...')\n",
        "        elif desired_sex == 'F':\n",
        "            print('Downloading only female subjects...')\n",
        "        else:\n",
        "            print('Please specify \\'M\\' or \\'F\\' for sex and try again')\n",
        "            sys.exit()\n",
        "    except TypeError:\n",
        "        desired_sex = None\n",
        "        print('No sex specified, using all sexes...')\n",
        "\n",
        "    # Call the collect and download routine\n",
        "    collect_and_download(desired_derivative, desired_pipeline, desired_strategy, download_data_dir, desired_age_max,\n",
        "                         desired_age_min, desired_site, desired_sex, desired_diagnosis)"
      ]
    }
  ]
}